{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW/NYALFgm8JXHuLnPWye6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmadbhi/Retail-Sales-Data-Analysis/blob/main/OLS_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi9eGrjOkTE5",
        "outputId": "29e86cbe-f164-4c13-c9a2-5e705aae7964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found. Please check the file path.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main():\n",
        "    # Load dataset (replace with your actual file path)\n",
        "    try:\n",
        "        df = pd.read_csv('/content/retail_sales_dataset.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: File not found. Please check the file path.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nInitial data:\")\n",
        "    print(df.head(8))\n",
        "    print(f\"\\nTotal rows and columns before cleaning: {df.shape}\")\n",
        "\n",
        "    # Data Cleaning - Option 1: Drop missing values\n",
        "    df_cleaned = df.dropna()\n",
        "    print(\"\\nData after dropping missing values:\")\n",
        "    print(df_cleaned.head(8))\n",
        "    print(f\"Rows/columns after dropping: {df_cleaned.shape}\")\n",
        "\n",
        "    # Data Cleaning - Option 2: Imputation\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    numeric_cols = ['Age', 'Quantity', 'Price per Unit', 'Total Amount']\n",
        "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "    print(\"\\nData after imputation:\")\n",
        "    print(df.head(8))\n",
        "    print(f\"Rows/columns after imputation: {df.shape}\")\n",
        "\n",
        "    # Categorical Encoding\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    df['Gender'] = le.fit_transform(df['Gender'])\n",
        "    print(\"\\nAfter Label Encoding (Gender):\")\n",
        "    print(df[['Gender']].head())\n",
        "\n",
        "    # One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=['Product Category'], drop_first=True)\n",
        "    print(\"\\nAfter One-Hot Encoding (Product Category):\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Feature Scaling\n",
        "    # Min-Max Scaling\n",
        "    minmax_cols = ['Quantity', 'Price per Unit', 'Total Amount']\n",
        "    scaler = MinMaxScaler()\n",
        "    df[minmax_cols] = scaler.fit_transform(df[minmax_cols])\n",
        "    print(\"\\nAfter Min-Max Scaling:\")\n",
        "    print(df[minmax_cols].head())\n",
        "\n",
        "    # Standardization\n",
        "    std_cols = ['Age', 'Quantity', 'Price per Unit', 'Total Amount']\n",
        "    std_scaler = StandardScaler()\n",
        "    df[std_cols] = std_scaler.fit_transform(df[std_cols])\n",
        "    print(\"\\nAfter Standardization:\")\n",
        "    print(df[std_cols].head())\n",
        "\n",
        "    # OLS Regression\n",
        "    X = df[['Price per Unit']]\n",
        "    y = df['Total Amount']\n",
        "    X = sm.add_constant(X)  # Add intercept term\n",
        "\n",
        "    model = sm.OLS(y, X).fit()\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"REGRESSION RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "    print(model.summary())\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(df['Price per Unit'], df['Total Amount'],\n",
        "                alpha=0.5, label='Actual Data')\n",
        "    plt.plot(df['Price per Unit'], model.predict(X),\n",
        "             color='red', linewidth=2, label='Regression Line')\n",
        "    plt.xlabel('Price per Unit')\n",
        "    plt.ylabel('Total Amount')\n",
        "    plt.title('Price vs. Total Sales')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "5DkswxvSkkRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "vNvhnqvokkt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df[['Price per Unit']] = scaler.fit_transform(df[['Price per Unit']])"
      ],
      "metadata": {
        "id": "5fGZYxcqnU1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}